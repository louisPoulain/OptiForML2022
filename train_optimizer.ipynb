{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train optimizer\n",
    "Notebook to train different optimizer to compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from tqdm.notebook import trange, tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell only if you run this notebook on Google Colab.\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "sys.path.append('/content/drive/My Drive/OPTIFORML2022')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from optimizer.AdaHessian import AdaHessian\n",
    "from optimizer.Atmo import Atmo, MASScheduler\n",
    "from dataset import ImagesDataset\n",
    "from model import ResNet18\n",
    "from path import TRAIN_HISTORY_DIR, TRAIN_MODEL_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose dataset\n",
    "data_name = \"MNIST\"\n",
    "#data_name = \"cifar\"\n",
    "full = False\n",
    "tiny = True\n",
    "\n",
    "# choose optimizer\n",
    "optimizer_name = \"adam\"\n",
    "optimizer_name = \"sgd\"\n",
    "optimizer_name = \"atmo\"\n",
    "optimizer_name = \"dynamicAtom\"\n",
    "#optimizer_name = \"adaHessian\"\n",
    "\n",
    "# choose nb of epochs\n",
    "epochs = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Using MNIST\n",
      "** Reduce the data-set to the tiny setup\n",
      "** Use 500 train samples\n",
      "* Using MNIST\n",
      "** Reduce the data-set to the tiny setup\n",
      "** Use 100 test samples\n"
     ]
    }
   ],
   "source": [
    "# load dataset\n",
    "train_dataset = ImagesDataset(full = full, tiny=tiny, cifar=(data_name==\"cifar\"))\n",
    "test_dataset = ImagesDataset(full = full, tiny=tiny, cifar=(data_name==\"cifar\"), test=True)\n",
    "\n",
    "\n",
    "trainDataLoader = torch.utils.data.DataLoader(train_dataset, batch_size=256, shuffle=True)\n",
    "testDataLoader = torch.utils.data.DataLoader(test_dataset, batch_size=256, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# load model\n",
    "model = ResNet18(in_channel=1 if data_name==\"MNIST\" else 3)\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "print(device)\n",
    "model.train()\n",
    "model.to(device)\n",
    "\n",
    "# load optimizer\n",
    "if optimizer_name == \"adam\":\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "if optimizer_name == \"sgd\":\n",
    "    optimizer = optim.SGD(model.parameters(), lr=1e-3)\n",
    "if optimizer_name == \"atmo\":\n",
    "    optimizer = Atmo(model.parameters())\n",
    "if optimizer_name == \"dynamicAtom\":\n",
    "    optimizer = Atmo(model.parameters(), adam_w=1, sgd_w=0)\n",
    "    dynamic = MASScheduler(optimizer, epochs = epochs)\n",
    "if optimizer_name == \"adaHessian\":\n",
    "    optimizer = AdaHessian(model.parameters())\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90ce9203ff224077bd7c84b6a62e0c23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/2 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffc5bff6d6b442b5a5f09f2bee222f00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train epoch 1:   0%|          | 0/2 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40e063f334364e59b23f2e63e0950a80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Test epoch 1:   0%|          | 0/1 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01d2aa20e0784c289420bf51a2c04af1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train epoch 2:   0%|          | 0/2 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f2ffdfdbce341eaa21cce0d32ccff06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Test epoch 2:   0%|          | 0/1 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_loss = []\n",
    "train_acc = []\n",
    "test_loss = []\n",
    "test_acc = []\n",
    "time_epoch = []\n",
    "\n",
    "with trange(1, epochs + 1, desc='Training', unit='epoch') as t:\n",
    "  for epoch in t:\n",
    "    losses = []\n",
    "    acc = []\n",
    "    start_time = time.time()\n",
    "    with tqdm(trainDataLoader, desc=f'Train epoch {epoch}',\n",
    "              unit='batch', leave=False) as t1:\n",
    "      for x_train, y_train in t1:\n",
    "        x_train = x_train.to(device)\n",
    "        y_train = y_train.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(x_train)\n",
    "        loss = criterion(output, y_train)\n",
    "        loss.backward(create_graph=(optimizer_name==\"adaHessian\"))\n",
    "        optimizer.step()\n",
    "\n",
    "        losses.append(loss)\n",
    "        pred = torch.argmax(output, axis = 1)\n",
    "        acc.append(sum(pred == y_train).item()/pred.shape[0])\n",
    "\n",
    "    if optimizer_name==\"dynamicAtmo\":\n",
    "          dynamic.step()\n",
    "\n",
    "    train_loss.append(sum(losses)/len(losses))\n",
    "    train_acc.append(sum(acc)/len(acc))\n",
    "\n",
    "    losses = []\n",
    "    acc = []\n",
    "    with torch.no_grad():\n",
    "      with tqdm(testDataLoader, desc=f'Test epoch {epoch}',\n",
    "                unit='batch', leave=False) as t1:\n",
    "        for x_test, y_test in t1:\n",
    "          x_test = x_test.to(device)\n",
    "          y_test = y_test.to(device)\n",
    "\n",
    "          output = model(x_test)\n",
    "          loss = criterion(output, y_test)\n",
    "          losses.append(loss)\n",
    "\n",
    "          pred = torch.argmax(output, axis = 1)\n",
    "          acc.append(sum(pred == y_test).item()/pred.shape[0])\n",
    "\n",
    "      test_loss.append(sum(losses)/len(losses))\n",
    "      test_acc.append(sum(acc)/len(acc))\n",
    "\n",
    "      end_time = time.time()\n",
    "      time_epoch.append(end_time-start_time)\n",
    "\n",
    "#mean by epoch\n",
    "time_epoch = sum(time_epoch)/len(time_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this cell to save history\n",
    "history = dict()\n",
    "history[\"train_loss\"] = train_loss\n",
    "history[\"train_acc\"] = train_acc\n",
    "history[\"test_loss\"] = test_loss\n",
    "history[\"test_acc\"] = test_acc\n",
    "history[\"time_epoch\"] = time_epoch\n",
    "history[\"data\"] = data_name\n",
    "history[\"model\"] = \"resnet18\"\n",
    "history[\"epochs\"] = epochs\n",
    "history[\"optimizer\"] = optimizer_name\n",
    "with open(os.path.join(TRAIN_HISTORY_DIR, f\"{optimizer_name}_{epochs}epochs_{data_name}.pickle\"), 'wb') as f:\n",
    "  pickle.dump(history, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this cell to save model\n",
    "weights = model.state_dict()\n",
    "torch.save(weights,os.path.join(TRAIN_MODEL_DIR, f\"{optimizer_name}_{epochs}epochs_{data_name}.pt\"))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "100425e406423ce956545b95bc1f6e6855675069bc773847139c573c06d47449"
  },
  "kernelspec": {
   "display_name": "Python 3.9.2 ('jupyterlab-debugger')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
